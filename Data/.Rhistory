transfer = TRUE,
path     = '/Users/aurelianosancho/Google Drive/Case_PosDoc',
verbose  = FALSE)
ncfile <- wf_request(user    = "85025",
request  = request,
transfer = TRUE,
path     = '/Users/aurelianosancho/Downloads/',
verbose  = FALSE)
###############################################################################
#
# Na segunda parte eu abro o arquivo netcdf que baixei, extraio os dados e
# coloco em um dataframe com as seguintes colunas: lon, lat e dados de temperatura por hora
# (como sao 5 dias e 24h por dia temos 120 colunas, 24 por dia)
#
##############################################################################
df <- nc_open("/Users/aurelianosancho/Downloads/era5-demo.nc")
print(df)
##############################################################################
df <- nc_open("/Users/aurelianosancho/Downloads/ERA5_SL_surface_pressure_2016-2020.nc")
print(df)
dname <- "ps"
tmp_array <- ncvar_get(df,dname)
tmp_array
dim(tmp_array)
tmp_array[1]
tmp_array[,:]
tmp_array[,1]
tmp_array[,1:2]
names(tmp_array)
tmp_array[1:20]
tmp_array[:,]
tmp_array[2,]
dim(tmp_array)
tmp_array[1][1,2]
dim(tmp_array)
tmp_array[1,1,1]
tmp_array[1,1,]
dim(tmp_array)
time <- ncvar_get(df,'time')
time
dim(time)
dim(tmp_array)
print(df)
library(sf)
library(sp)
library(spdep)
library(tidyverse)
library(rgdal)
library(raster)
library(ecmwfr)
library(ncdf4)
library(maptools)
library(rgeos)
library(ncdfgeom)
library(dplyr)
##############################################################################
df <- nc_open("/Users/aurelianosancho/Downloads/ERA5_SL_surface_pressure_2016-2020.nc")
print(df)
lon <- ncvar_get(df,"longitude")
lon <- ncvar_get(df,"lon")
nlon <- dim(lon)
lat <- ncvar_get(df,"lat")
nlat <- dim(lat)
time <- ncvar_get(df,"time")
tunits <- ncatt_get(df,"time","units")
nt <- dim(time)
dname <- "sp"
tmp_array <- ncvar_get(df,dname)
dname <- "ps"
tmp_array <- ncvar_get(df,dname)
dlname <- ncatt_get(df,dname,"long_name")
dunits <- ncatt_get(df,dname,"units")
fillvalue <- ncatt_get(df,dname,"_FillValue")
tmp_array[tmp_array==fillvalue$value] <- NA
tmp_vec_long <- as.vector(tmp_array)
tmp_mat <- matrix(tmp_vec_long, nrow=nlon*nlat, ncol=nt)
dim(tmp_mat)
head(na.omit(tmp_mat))
lonlat <- as.matrix(expand.grid(lon,lat))
tmp_df02 <- data.frame(cbind(lonlat,tmp_mat))
names(tmp_df02) <- c("lon","lat")
head(tmp_df02,2)
tmp_df02 <- data.frame(cbind(lonlat,tmp_mat))
head(tmp_df02,2)
tmp_array <- ncvar_get(df,dname)
head(tmp_array,2)
tmp_array[1,1,1]
library(sf)
library(sp)
library(spdep)
library(tidyverse)
library(rgdal)
library(raster)
library(ecmwfr)
library(ncdf4)
library(maptools)
library(rgeos)
library(ncdfgeom)
library(dplyr)
library(spatialEco)
library(sqldf)
library(chron)
library(lattice)
library(RColorBrewer)
wf_set_key(user = "85025",
key = "9723d098-0332-4f15-9cc3-6f5997fde1f5",
service = "cds")
request <- list("dataset_short_name" = "reanalysis-era5-single-levels",
"product_type"   = "reanalysis",
"variable"       = "2m_temperature",
"year"           = "2010",
"month"          = "07",
"day"            = str_pad(1:5,1,"left","0"),
"time"           = str_c(0:23,"00",sep=":")%>%str_pad(5,"left","0"),
"area"           = "6/-74/-35/-35",
"format"         = "netcdf",
"target"         = "era5-demo.nc")
ncfile <- wf_request(user    = "85025",
request  = request,
transfer = TRUE,
path     = '/Users/aurelianosancho/Downloads/',
verbose  = FALSE)
###############################################################################
#
# Na segunda parte eu abro o arquivo netcdf que baixei, extraio os dados e
# coloco em um dataframe com as seguintes colunas: lon, lat e dados de temperatura por hora
# (como sao 5 dias e 24h por dia temos 120 colunas, 24 por dia)
#
##############################################################################
df <- nc_open("/Users/aurelianosancho/Downloads/era5-demo.nc")
dname <- "t2m"
tmp_array <- ncvar_get(df,dname)
dim(tmp_array)
##############################################################################
df <- nc_open("/Users/aurelianosancho/Downloads/ERA5_SL_surface_pressure_2016-2020.nc")
print(df)
dname <- "ps"
tmp_array <- ncvar_get(df,dname)
dim(tmp_array)
str_c(0:23,"00",sep=":")%>%str_pad(5,"left","0")
str_pad(1:5,1,"left","0")
dim(tmp_array)
data <- ncvar_get(df,"year")
data <- ncvar_get(df,"day")
df$is_GMT
df$var$ps$
ds = netCDF4.Dataset("/Users/aurelianosancho/Downloads/ERA5_SL_surface_pressure_2016-2020.nc", 'r')
library(netCDF4)
##############################################################################
dat.nc <- nc_open("/Users/aurelianosancho/Downloads/ERA5_SL_surface_pressure_2016-2020.nc")
lon <- ncvar_get(dat.nc,"x");# extracts longitude
lon <- ncvar_get(dat.nc,"lon");# extracts longitude
nlon <- dim(lon);# returns the number of records
lat <- ncvar_get(dat.nc,"lat");# extracts latitude
nlat <- dim(lat);# returns the number of records
time <- ncvar_get(dat.nc,"time");# extracts time
tunits <- ncatt_get(dat.nc,"time","units");# assigns units to time
tunits
nt <- dim(time)
dname="ps"
tmp_array <- ncvar_get(dat.nc,dname)
dlname <- ncatt_get(dat.nc,dname,"long_name")
dunits <- ncatt_get(dat.nc,dname,"units")
fillvalue <- ncatt_get(dat.nc,dname,"_FillValue")
# get global attributes
title <- ncatt_get(dat.nc,0,"title")
institution <- ncatt_get(dat.nc,0,"institution")
datasource <- ncatt_get(dat.nc,0,"source")
references <- ncatt_get(dat.nc,0,"references")
history <- ncatt_get(dat.nc,0,"history")
Conventions <- ncatt_get(dat.nc,0,"Conventions")
tustr <- strsplit(tunits$value, " ")
tdstr <- strsplit(unlist(tustr)[3], "-")
tmonth <- as.integer(unlist(tdstr)[2])
tday <- as.integer(substring(unlist(tdstr)[3],1,2))
tyear <- as.integer(unlist(tdstr)[1])
time.val=as.Date(chron(time,origin=c(tmonth, tday, tyear)))
head(time.val)
time.val
min(time.val)
max(time.val)
length(time.val)
tunits
tunits <- "days since 2016-01-01 00:00:00"
nt <- dim(time)
dname="ps"
tmp_array <- ncvar_get(dat.nc,dname)
dlname <- ncatt_get(dat.nc,dname,"long_name")
dunits <- ncatt_get(dat.nc,dname,"units")
fillvalue <- ncatt_get(dat.nc,dname,"_FillValue")
# get global attributes
title <- ncatt_get(dat.nc,0,"title")
institution <- ncatt_get(dat.nc,0,"institution")
datasource <- ncatt_get(dat.nc,0,"source")
references <- ncatt_get(dat.nc,0,"references")
history <- ncatt_get(dat.nc,0,"history")
Conventions <- ncatt_get(dat.nc,0,"Conventions")
tustr <- strsplit(tunits$value, " ")
tunits <- ncatt_get(dat.nc,"time","units");# assigns units to time
tunits
tunits$value
dim(tunits)
tunits
tunits[2]
tmonth
tyear
time.val=as.Date(chron(time,origin=c(1, 1, 2016)))
head(time.val)
dat.nc
print(df)
time <- ncvar_get(df,"time")
time
time.val
timestamp()
##------ Sun Aug  8 21:59:06 2021 ------##
time.val
max(time.val)
min(time.val)
time <- ncvar_get(df,"time")
length(time)
rm(list = ls())
setwd("/Users/aurelianosancho/Dropbox/MS182 - Cardiovascular Risk/Data/MS182 - Live Birth Data/Notebooks/")
library("cwhmisc")
library("Hmisc")
library("psych")
library("rgl")
library("mixtools")
library("mclust")
library(flexmix)
library(betareg)
source("betamix2.R")
library(factoextra)
library(NbClust)
library("paran")
library("sf")
library("rnaturalearth")
library("rnaturalearthdata")
library("RColorBrewer")
library("classInt")
library(maptools)
library(maps)
library("ggmap")
library(rgeos)
library("rnaturalearth")
library("rnaturalearthdata")
library(sp)
library(RColorBrewer) # creates nice color schemes
library(classInt)
##
if(!require(dplyr)){ install.packages("dplyr"); require(dplyr)}
if(!require(tidyverse)){ install.packages("tidyverse"); require(tidyverse)}
if(!require(rgdal)){ install.packages("rgdal"); require(rgdal)}
if(!require(readxl)){ install.packages("readxl"); require(readxl)}
if(!require(rgeos)){ install.packages("rgeos"); require(rgeos)}
if(!require(hrbrthemes)){ install.packages("hrbrthemes"); require(hrbrthemes)}
if(!require(data.table)){ install.packages("data.table"); require(data.table)}
if(!require(lme4)){ install.packages("lme4"); require(lme4)}
if(!require(clusterSim)){ install.packages("clusterSim"); require(clusterSim)}
if(!require(viridis)){ install.packages("viridis"); require(viridis)}
if(!require(ggplot2)){ install.packages("ggplot2"); require(ggplot2)}
if(!require(sqldf)){ install.packages("sqldf"); require(sqldf)}
if(!require(corrplot)){ install.packages("corrplot"); require(corrplot)}
if(!require(PerformanceAnalytics)){ install.packages("PerformanceAnalytics"); require(PerformanceAnalytics)}
if(!require(devtools)){ install.packages("devtools"); require(devtools)}
if(!require(xlsx)){ install.packages("xlsx"); require(xlsx)}
df <- read_csv('/Users/aurelianosancho/Dropbox/MS182 - Cardiovascular Risk/Data/MS182 - Live Birth Data/new_data.csv')
################################################################################
df <-subset(df, select=c(BTHBIRTHSL1AD,BTHMBIRTHSL1AD,BTHFBIRTHSL1AD,
perc_male,perc_female)) # 6 selected vars
df
df <- data.Normalization(df,type="n4");
df
df <- data.Normalization(df,type="n4");
df[,c(1,2,3,4,5)] <- data.Normalization(df[,c(1,2,3,4,5)],type="n4");
length(df)
length(df$BTHBIRTHSL1AD)
df[,c(1,2,3,4,5)] <- data.Normalization(df[,c(1,2,3,4,5)],type="n4");
df <- data.Normalization(df,type="n4",normalization = "column",na.rm=FALSE);
data(data_ratio)
z1 <- data.Normalization(data_ratio,type="n1",normalization="column",na.rm=FALSE)
data_ratio
df <- read_csv('/Users/aurelianosancho/Dropbox/MS182 - Cardiovascular Risk/Data/MS182 - Live Birth Data/new_data.csv')
df <- data.Normalization(df,type="n4",normalization = "column",na.rm=FALSE);
################################################################################
df <-subset(df, select=c(BTHBIRTHSL1AD,BTHMBIRTHSL1AD,BTHFBIRTHSL1AD,
perc_male,perc_female)) # 6 selected vars
length(df$BTHBIRTHSL1AD)
df <- data.Normalization(df,type="n4",normalization = "column",na.rm=FALSE);
df2 <- data.Normalization(df$BTHBIRTHSL1AD,type="n4",normalization = "column",na.rm=FALSE);
df2
df2 <- data.Normalization(df[,c(1,2)],type="n4",normalization = "column",na.rm=FALSE);
df2 <- data.Normalization(df[,c(1,3)],type="n4",normalization = "column",na.rm=FALSE);
df
df <- read_csv('/Users/aurelianosancho/Dropbox/MS182 - Cardiovascular Risk/Data/MS182 - Live Birth Data/new_data.csv')
df <- read_csv('/Users/aurelianosancho/Dropbox/MS182 - Cardiovascular Risk/Data/MS182 - Live Birth Data/new_data.csv')
################################################################################
df_cluster <-subset(df, select=c(BTHBIRTHSL1AD,BTHMBIRTHSL1AD,BTHFBIRTHSL1AD,
perc_male,perc_female)) # 6 selected vars
df
df_cluster<- data.Normalization(df_cluster,type="n4",normalization = "column",na.rm=FALSE);
df_cluster
mbeta6c <- flexmix(formula=.~1,
data=df_cluster , k=6, control=list(minprior=0.1))
df_cluster[,c(1,2)] <- data.Normalization(df_cluster[,c(1,2)],type="n4",normalization = "column",na.rm=FALSE);
rm(list = ls())
setwd("/Users/aurelianosancho/Dropbox/MS182 - Cardiovascular Risk/Data/MS182 - Live Birth Data/Notebooks/")
##
if(!require(dplyr)){ install.packages("dplyr"); require(dplyr)}
if(!require(tidyverse)){ install.packages("tidyverse"); require(tidyverse)}
if(!require(rgdal)){ install.packages("rgdal"); require(rgdal)}
if(!require(readxl)){ install.packages("readxl"); require(readxl)}
if(!require(rgeos)){ install.packages("rgeos"); require(rgeos)}
if(!require(hrbrthemes)){ install.packages("hrbrthemes"); require(hrbrthemes)}
if(!require(data.table)){ install.packages("data.table"); require(data.table)}
if(!require(lme4)){ install.packages("lme4"); require(lme4)}
if(!require(clusterSim)){ install.packages("clusterSim"); require(clusterSim)}
if(!require(viridis)){ install.packages("viridis"); require(viridis)}
if(!require(ggplot2)){ install.packages("ggplot2"); require(ggplot2)}
if(!require(sqldf)){ install.packages("sqldf"); require(sqldf)}
if(!require(corrplot)){ install.packages("corrplot"); require(corrplot)}
if(!require(PerformanceAnalytics)){ install.packages("PerformanceAnalytics"); require(PerformanceAnalytics)}
if(!require(devtools)){ install.packages("devtools"); require(devtools)}
if(!require(xlsx)){ install.packages("xlsx"); require(xlsx)}
df <- read_csv('/Users/aurelianosancho/Dropbox/MS182 - Cardiovascular Risk/Data/MS182 - Live Birth Data/new_data.csv')
################################################################################
df_cluster <-subset(df, select=c(BTHBIRTHSL1AD,BTHMBIRTHSL1AD,BTHFBIRTHSL1AD,
perc_male,perc_female)) # 6 selected vars
df_cluster
library(sf)
library(sp)
library(spdep)
library(tidyverse)
library(rgdal)
library(raster)
library(ecmwfr)
library(ncdf4)
library(maptools)
library(rgeos)
library(ncdfgeom)
library(dplyr)
library(spatialEco)
library(sqldf)
library(chron)
library(lattice)
library(RColorBrewer)
##########################################################################
#
# Nesta primeira parte eu faco o download dos dados via uma API
#
##########################################################################
wf_set_key(user = "85025",
key = "9723d098-0332-4f15-9cc3-6f5997fde1f5",
service = "cds")
request <- list("dataset_short_name" = "reanalysis-era5-single-levels",
"product_type"   = "reanalysis",
"variable"       = "2m_temperature",
"year"           = "2010",
"month"          = "07",
"day"            = str_pad(1:5,1,"left","0"),
"time"           = str_c(0:23,"00",sep=":")%>%str_pad(5,"left","0"),
"area"           = "6/-74/-35/-35",
"format"         = "netcdf",
"target"         = "era5-demo.nc")
ncfile <- wf_request(user    = "85025",
request  = request,
transfer = TRUE,
path     = '/Users/aurelianosancho/Downloads',
verbose  = FALSE)
str_pad(1:5,1,"left","0")
wf_set_key(user = "85025",
key = "9723d098-0332-4f15-9cc3-6f5997fde1f5",
service = "cds")
request <- list("dataset_short_name" = "reanalysis-era5-single-levels",
"product_type"   = "reanalysis",
"variable"       = "2m_temperature",
"year"           = "2010",
"month"          = "07",
"day"            = str_pad(1:5,1,"left","0"),
"time"           = str_c(0:23,"00",sep=":")%>%str_pad(5,"left","0"),
"area"           = "6/-74/-35/-35",
"format"         = "netcdf",
'grid'           = "0.25",
"target"         = "era5-demo.nc")
ncfile <- wf_request(user    = "85025",
request  = request,
transfer = TRUE,
path     = '/Users/aurelianosancho/Downloads',
verbose  = FALSE)
## \\\\\\\\\\\\\\ ##
## \\\\ ERA 5 \\\ ##
## \\\\\\\\\\\\\\ ##
library(raster) ; library(rgdal) ;library(ncdf4) ; library(sf);library(sp);
library(stringr); library(data.table); library(maptools) ; library(lubridate)
setwd ("H:\\Desktop\\Rochelle_LSHTMdesktop\\Space4health_Brazil")
####  GREAT BRITAIN BOUNDARY - GEOG + PROJECTION BNG
poly <- sf::read_sf("/Users/aurelianosancho/Documents/GitHub/ERA5_download_and_table/Data/BR_UF_2020.shp")
####  GREAT BRITAIN BOUNDARY - GEOG + PROJECTION BNG
poly <- sf::read_sf("/Users/aurelianosancho/Documents/GitHub/ERA5_download_and_table/Data/BR_UF_2020.shp")
setwd ("/Users/aurelianosancho/Documents/GitHub/ERA5_download_and_table/Data/")
####  GREAT BRITAIN BOUNDARY - GEOG + PROJECTION BNG
poly <- sf::read_sf("/Users/aurelianosancho/Documents/GitHub/ERA5_download_and_table/Data/BR_UF_2020.shp")
####  GREAT BRITAIN BOUNDARY - GEOG + PROJECTION BNG
poly <- sf::read_sf("/Users/aurelianosancho/Documents/GitHub/ERA5_download_and_table/Data/BR_UF_2020.shp")
####  GREAT BRITAIN BOUNDARY - GEOG + PROJECTION BNG
poly <- sf::read_sf("/Users/aurelianosancho/Documents/GitHub/ERA5_download_and_table/Data/AL_Municipios_2020.shp")
## \\\\\\\\\\\\\\ ##
## \\\\ ERA 5 \\\ ##
## \\\\\\\\\\\\\\ ##
library(raster) ; library(rgdal) ;library(ncdf4) ; library(sf);library(sp);
library(stringr); library(data.table); library(maptools) ; library(lubridate)
setwd ("/Users/aurelianosancho/Documents/GitHub/ERA5_download_and_table/Data/")
####  GREAT BRITAIN BOUNDARY - GEOG + PROJECTION BNG
poly <- sf::read_sf("/Users/aurelianosancho/Documents/GitHub/ERA5_download_and_table/Data/BR_UF_2020.shp")
### IT IS ONLY ONE FILE WITH ALL 2m TEMP
files  <- "/Users/aurelianosancho/Documents/GitHub/ERA5_download_and_table/Data/temp_era5.nc"
### IT IS ONLY ONE FILE WITH ALL 2m TEMP
nc  <- "/Users/aurelianosancho/Documents/GitHub/ERA5_download_and_table/Data/temp_era5.nc"
"
"
## FROM "files.1" EXTRACT THE VARIABLES' NAME
dname <- names(nc$var)[1] #"t2m"
### IT IS ONLY ONE FILE WITH ALL 2m TEMP
nc  <- "/Users/aurelianosancho/Documents/GitHub/ERA5_download_and_table/Data/temp_era5.nc"
## FROM "files.1" EXTRACT THE VARIABLES' NAME
dname <- names(nc$var)[1] #"t2m"
### IT IS ONLY ONE FILE WITH ALL 2m TEMP
nc <- nc_open("/Users/aurelianosancho/Documents/GitHub/ERA5_download_and_table/Data/temp_era5.nc")
dname <- names(nc$var)[1] #"t2m"
temp <- brick(file.1[[1]], varname=dname, stopIfNotEqualSpaced=FALSE)
temp <- brick(nc[[1]], varname=dname, stopIfNotEqualSpaced=FALSE)
dim(temp) #161 157  30
temp.day <- temp[[15]]
dim(temp) #161 157  30
plot(temp.day)
crs(temp)
erat.df <- as.data.frame(temp[[1]], xy=TRUE, centroids=TRUE)
head(erat.df)
nrow(erat.df) #25277 (ALL PIXELS)
## INCLUDE THE ID CELL
erat.df$era5.id <- as.numeric(rownames(erat.df))
erat.df
## FROM DATA.FRAME TO DATA.TABLE
erat.df <- data.table(erat.df)
temp <- brick(nc[[1]], varname=dname, stopIfNotEqualSpaced=FALSE)
dim(temp) #161 157  30
temp.day <- temp[[1]] ## nao entendi
plot(temp.day)
crs(temp)
erat.df <- as.data.frame(temp[[1]], xy=TRUE, centroids=TRUE)
head(erat.df)
nrow(erat.df) #25277 (ALL PIXELS)
## INCLUDE THE ID CELL
erat.df$era5.id <- as.numeric(rownames(erat.df))
erat.df
## FROM DATA.FRAME TO DATA.TABLE
erat.df <- data.table(erat.df)
## FROM DATA.TABLE TO SHAPEFILE
erat.shp <- st_as_sf(erat.df, coords = c("x", "y"), crs = "+proj=longlat +datum=WGS84 +no_defs")
erat.shp <- sf::st_transform(erat.shp, st_crs(poly))
erat.shp
## SELECT THE POINTS LOCATED INSIDE
erat.br = erat.shp[poly, ]
nrow(data.frame(erat.br))
sf::st_write(erat.br,"/Users/aurelianosancho/Documents/GitHub/ERA5_download_and_table/Data/ERA5_2mt_BR_GRS80.shp",driver = "ESRI Shapefile")
## GET THE NEAREST ERA5 GRID CELL FOR EACH OS.GRID
grid.era = st_join(poly, erat.br)
head(data.frame(grid.era))
nrow(data.frame(grid.era))
grid.eradf <- data.frame(grid.era)
length(unique(grid.era$era5.id))
grid.eradf <- grid.eradf[ , -c(5:6)]
names(grid.eradf)
head(grid.eradf)
saveRDS(grid.eradf, "/Users/aurelianosancho/Documents/GitHub/ERA5_download_and_table/Data/UF_era5id_lookup.RDS")
###CREATE A LOOKUP TABLE IN A SHAPEFILEFORMAT
grid.era.shp <- merge(erat.shp, grid.eradf, by="era5.id")
head(grid.era.shp)
sf::st_write(grid.era.shp,"/Users/aurelianosancho/Documents/GitHub/ERA5_download_and_table/Data/ERA5_BR_GRS80_pt.shp",driver = "ESRI Shapefile")
### IT IS ONLY ONE FILE WITH ALL 2m TEMP
files  <- "/Users/aurelianosancho/Documents/GitHub/ERA5_download_and_table/Data/temp_era5.nc"
file.1 <- nc_open(files)
file.1
## FROM "files.1" EXTRACT THE VARIABLES' NAME
dname <- names(file.1$var)[1] #"t2m"
temp <- brick(file.1[[1]], varname=dname, stopIfNotEqualSpaced=FALSE)
dim(temp) #401 391   6
temp.day <- temp[[1]]
plot(temp.day)
crs(temp)
erat.df <- as.data.frame(temp[[1]], xy=TRUE, centroids=TRUE)
head(erat.df)
nrow(erat.df) #156791 (ALL PIXELS)
## INCLUDE THE ID CELL
erat.df$era5land.id <- as.numeric(rownames(erat.df))
## FROM DATA.FRAME TO DATA.TABLE
erat.df <- data.table(erat.df)
## FROM DATA.TABLE TO SHAPEFILE
erat.shp<- st_as_sf(erat.df, coords = c("x", "y"), crs = "+proj=longlat +datum=WGS84 +no_defs")
erat.shp <- sf::st_transform(erat.shp, st_crs(poly))
## SELECT THE POINTS LOCATED INSIDE GREAT BRITAIN
erat.br = erat.shp[poly, ]
nrow(data.frame(erat.br)) #70922
## GET THE NEAREST ERA5 GRID CELL FOR EACH OS.GRID
grid.era = st_join(poly, erat.br)
head(data.frame(grid.era))
nrow(data.frame(grid.era))
grid.eradf <- data.frame(grid.era)
length(unique(grid.era$era5land.id))
grid.eradf <- grid.eradf[ , -c(5:6)]
names(grid.eradf)
head(grid.eradf)
saveRDS(grid.eradf, "H:\\Desktop\\Rochelle_LSHTMdesktop\\Space4health_Brazil\\processed\\UF_era5idLand_lookup.RDS")
